name: Build and Deploy Documentation to S3

on:
  push:
    branches:
      - main
      - master
  pull_request:
    branches:
      - main
      - master
  workflow_dispatch:
    inputs:
      triggered_by:
        description: 'Repository that triggered this build'
        required: false
        type: string
  repository_dispatch:
    types: [trigger-docs-update]
  schedule:
    # Run weekly on Monday at 2 AM UTC to pull latest content from all repos
    # (Automatic triggers handle immediate updates, this is a fallback)
    - cron: '0 2 * * 1'

env:
  # S3 Configuration - Update these or use repository secrets
  AWS_REGION: us-east-1
  S3_BUCKET: ${{ secrets.S3_BUCKET_NAME }}
  CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Checkout central documentation repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Log trigger information
        run: |
          echo "=== Workflow Trigger Information ==="
          echo "Event: ${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
            echo "Triggered by external repository push"
            echo "Repository: ${{ github.event.client_payload.repository || 'unknown' }}"
            echo "Branch: ${{ github.event.client_payload.branch || 'unknown' }}"
            echo "Commit: ${{ github.event.client_payload.commit || 'unknown' }}"
            echo "AsyncAPI changed: ${{ github.event.client_payload.asyncapi_changed || 'false' }}"
          elif [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manually triggered"
            echo "Triggered by input: ${{ inputs.triggered_by || 'manual' }}"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            echo "Scheduled daily update"
          fi

      - name: Determine trigger repository
        id: trigger_repo
        run: |
          if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
            TRIGGER_REPO="${{ github.event.client_payload.repository }}"
            echo "repository=$TRIGGER_REPO" >> $GITHUB_OUTPUT
            echo "Triggered by repository: $TRIGGER_REPO"
          else
            echo "repository=" >> $GITHUB_OUTPUT
            echo "Not triggered by repository_dispatch, will pull from all repos"
          fi

      - name: Pull content from external repositories
        env:
          # Optional: Add authentication tokens if repos are private
          MESSAGING_CORE_REPO_TOKEN: ${{ secrets.MESSAGING_CORE_REPO_TOKEN || '' }}
          VIRTUAL_GOLF_GAME_API_REPO_TOKEN: ${{ secrets.VIRTUAL_GOLF_GAME_API_REPO_TOKEN || '' }}
          # Pass the triggering repository to the script
          TRIGGER_REPOSITORY: ${{ steps.trigger_repo.outputs.repository }}
        run: |
          python scripts/pull_content.py

      - name: Build documentation
        run: |
          mkdocs build --strict

      - name: Configure AWS credentials
        if: (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event_name == 'repository_dispatch' || github.event_name == 'schedule')
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # Option 1: Use OIDC (recommended for GitHub Actions)
          # role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          # aws-region: ${{ env.AWS_REGION }}
          
          # Option 2: Use Access Keys (simpler setup)
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy to S3
        if: (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event_name == 'repository_dispatch' || github.event_name == 'schedule')
        run: |
          # Sync built site to S3 bucket
          aws s3 sync ./site s3://${{ env.S3_BUCKET }} \
            --delete \
            --cache-control "max-age=86400" \
            --exclude "*.html" \
            --exclude "sitemap.xml"
          
          # Upload HTML files with shorter cache
          aws s3 sync ./site s3://${{ env.S3_BUCKET }} \
            --cache-control "max-age=3600" \
            --content-type "text/html" \
            --exclude "*" \
            --include "*.html"
          
          # Upload sitemap
          aws s3 cp ./site/sitemap.xml s3://${{ env.S3_BUCKET }}/sitemap.xml \
            --cache-control "max-age=3600" \
            --content-type "application/xml" || true
          
          echo "Documentation deployed to S3 bucket: ${{ env.S3_BUCKET }}"

      - name: Invalidate CloudFront cache
        if: (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event_name == 'repository_dispatch' || github.event_name == 'schedule') && env.CLOUDFRONT_DISTRIBUTION_ID != ''
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${{ env.CLOUDFRONT_DISTRIBUTION_ID }} \
            --paths "/*"
          echo "CloudFront cache invalidated"

      - name: Build documentation (PR preview)
        if: github.event_name == 'pull_request'
        run: |
          echo "Documentation built successfully. Review the changes in the PR."
          echo "Site contents:"
          ls -la ./site/
